{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages I will need\n",
    "from lex_processing import * \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To show plots in notebook\n",
    "%matplotlib inline  \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path is where the data I want to process is.\n",
    "# For Mac\n",
    "pathReagan = '/Users/Joe/dropbox/Data/Edited Data/Presidents Data/ReaganSpeeches/'\n",
    "pathBush = '/Users/Joe/dropbox/Data/Edited Data/Presidents Data/BushSpeeches/'\n",
    "pathTrump = '/Users/Joe/dropbox/Data/Edited Data/Presidents Data/TrumpSpeeches/'\n",
    "# For Linux\n",
    "#pathReagan = '/home/CAMPUS/alcantaj/Dropbox/Data/Edited Data/Presidents Data/ReaganSpeeches/'\n",
    "#pathBush = '/home/CAMPUS/alcantaj/Dropbox/Data/Edited Data/Presidents Data/BushSpeeches/'\n",
    "#pathTrump = '/home/CAMPUS/alcantaj/Dropbox/Data/Edited Data/Presidents Data/TrumpSpeeches/'\n",
    "# For Windows\n",
    "# pathReagan = '/Users/jomar/Dropbox/Data/Edited Data/Presidents Data/ReaganSpeeches/'\n",
    "#pathBush = '/Users/jomar/Dropbox/Data/Edited Data/Presidents Data/BushSpeeches/'\n",
    "#pathTrump = '/Users/jomar/Dropbox/Data/Edited Data/Presidents Data/TrumpSpeeches/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Frames for the datasets. I am including one data frame for 2 terms of Reagan\n",
    "# and 2 separate dataframes for each term.\n",
    "dfReagan = pd.DataFrame()\n",
    "dfReaganTerm1 = pd.DataFrame()\n",
    "dfReaganTerm2 = pd.DataFrame()\n",
    "dfBush = pd.DataFrame()\n",
    "dfTrump = pd.DataFrame()\n",
    "LIWC = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(pathReagan):\n",
    "    if filename.endswith('txt'):\n",
    "        f = open(pathReagan + filename)\n",
    "        raw = f.read()\n",
    "        # Clear raw of punctuation and tokenize for word counts.\n",
    "        wordsNoPunct = strip_punctuation(raw)\n",
    "        #hesitations = wordsNoPunct.count('—')\n",
    "        wordsNoPunct.replace(\"—\", ' ')\n",
    "        wordsNoPunct = word_tokenize(wordsNoPunct)\n",
    "        words = word_tokenize(raw)\n",
    "        # Word Counts for certain words\n",
    "        c = Counter(words)\n",
    "        Fillers = c['well'] + c['so'] + c['basically'] + c['actually'] + c['literally'] + c['um'] + c['ah']\n",
    "        NSNouns = c['something'] + c['anything'] + c['thing'] + c['everything']\n",
    "        LIVerbs = c['be'] + c['come'] + c['do'] + c['get'] + c['give'] + c['go'] + c['have'] + c['know'] + c['look']\n",
    "        + c['make'] + c['see'] + c['tell'] + c['think'] + c['want']\n",
    "        \n",
    "        sents = sent_tokenize(raw)\n",
    "        processed = preprocess(raw)\n",
    "        lex = lexical_diversity(wordsNoPunct)\n",
    "        mls = meanLengthSentence(processed)\n",
    "        wordDict = wordCount(processed)\n",
    "        thetuple = {'Filename': filename, 'TTR': lex,\n",
    "                    'WordCount':len(wordsNoPunct), \n",
    "                    'UniqueWords':len(set(wordsNoPunct)), \n",
    "                    'MLU': mls, 'Fillers': Fillers,\n",
    "                   'NSNouns': NSNouns, 'LIVerbs': LIVerbs}\n",
    "        finalDict = {**thetuple, **wordDict}\n",
    "        dfReagan = dfReagan.append(finalDict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(pathBush):\n",
    "    if filename.endswith('txt'):\n",
    "        f = open(pathBush + filename)\n",
    "        raw = f.read()\n",
    "        # Clear raw of punctuation and tokenize for word counts.\n",
    "        wordsNoPunct = strip_punctuation(raw)\n",
    "        #hesitations = wordsNoPunct.count('-')\n",
    "        wordsNoPunct.replace(\"-\", ' ')\n",
    "        wordsNoPunct = word_tokenize(wordsNoPunct)\n",
    "        \n",
    "        words = word_tokenize(raw)\n",
    "        # Word Counts for certain words\n",
    "        c = Counter(words)\n",
    "        Fillers = c['well'] + c['so'] + c['basically'] + c['actually'] + c['literally'] + c['um'] + c['ah']\n",
    "        NSNouns = c['something'] + c['anything'] + c['thing']\n",
    "        LIVerbs = c['be'] + c['come'] + c['do'] + c['get'] + c['give'] + c['go'] + c['have'] + c['know'] + c['look']\n",
    "        + c['make'] + c['see'] + c['tell'] + c['think'] + c['want']\n",
    "        \n",
    "        sents = sent_tokenize(raw)\n",
    "        processed = preprocess(raw)\n",
    "        lex = lexical_diversity(wordsNoPunct)\n",
    "        mls = meanLengthSentence(processed)\n",
    "        wordDict = wordCount(processed)\n",
    "        thetuple = {'Filename': filename, 'TTR': lex,\n",
    "                    'WordCount':len(wordsNoPunct), \n",
    "                    'UniqueWords':len(set(wordsNoPunct)), \n",
    "                    'MLU': mls, 'Fillers': Fillers,\n",
    "                   'NSNouns': NSNouns, 'LIVerbs': LIVerbs}\n",
    "        finalDict = {**thetuple, **wordDict}\n",
    "        dfBush = dfBush.append(finalDict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(pathTrump):\n",
    "    if filename.endswith('txt'):\n",
    "        f = open(pathTrump + filename)\n",
    "        raw = f.read()\n",
    "        # Clear raw of punctuation and tokenize for word counts.\n",
    "        wordsNoPunct = strip_punctuation(raw)\n",
    "        #hesitations = wordsNoPunct.count('-')\n",
    "        wordsNoPunct.replace(\"-\", ' ')\n",
    "        wordsNoPunct = word_tokenize(wordsNoPunct)\n",
    "        \n",
    "        words = word_tokenize(raw)\n",
    "        # Word Counts for certain words\n",
    "        c = Counter(words)\n",
    "        Fillers = c['well'] + c['so'] + c['basically'] + c['actually'] + c['literally'] + c['um'] + c['ah']\n",
    "        NSNouns = c['something'] + c['anything'] + c['thing']\n",
    "        LIVerbs = c['be'] + c['come'] + c['do'] + c['get'] + c['give'] + c['go'] + c['have'] + c['know'] + c['look']\n",
    "        + c['make'] + c['see'] + c['tell'] + c['think'] + c['want']\n",
    "        \n",
    "        sents = sent_tokenize(raw)\n",
    "        processed = preprocess(raw)\n",
    "        lex = lexical_diversity(wordsNoPunct)\n",
    "        mls = meanLengthSentence(processed)\n",
    "        wordDict = wordCount(processed)\n",
    "        thetuple = {'Filename': filename, 'TTR': lex,\n",
    "                    'WordCount':len(wordsNoPunct), \n",
    "                    'UniqueWords':len(set(wordsNoPunct)), \n",
    "                    'MLU': mls, 'Fillers': Fillers,\n",
    "                   'NSNouns': NSNouns, 'LIVerbs': LIVerbs}\n",
    "        finalDict = {**thetuple, **wordDict}\n",
    "        dfTrump = dfTrump.append(finalDict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mac\n",
    "testpath = '/Users/Joe/Documents/NLP/'\n",
    "# For Linux\n",
    "# testpath = '/home/CAMPUS/alcantaj/Documents/NLP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC = pd.read_csv(testpath + \"LIWC2015Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReagan = pd.merge(dfReagan, LIWC, on='Filename', how='inner')\n",
    "dfTrump = pd.merge(dfTrump, LIWC, on='Filename', how='inner')\n",
    "dfBush = pd.merge(dfBush, LIWC, on='Filename', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging Columns\n",
    "inserted_cols = ['Filename', 'TTR','WordCount', 'UniqueWords', 'MLU', 'Fillers', 'NSNouns', 'LIVerbs']\n",
    "cols = ([col for col in inserted_cols if col in dfReagan] \n",
    "        + [col for col in dfReagan if col not in inserted_cols])\n",
    "dfReagan = dfReagan[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging Columns\n",
    "inserted_cols = ['Filename', 'TTR','WordCount', 'UniqueWords', 'MLU', 'Fillers', 'NSNouns', 'LIVerbs']\n",
    "cols = ([col for col in inserted_cols if col in dfBush] \n",
    "        + [col for col in dfBush if col not in inserted_cols])\n",
    "dfBush = dfBush[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging Columns\n",
    "inserted_cols = ['Filename', 'TTR','WordCount', 'UniqueWords', 'MLU', 'Fillers', 'NSNouns', 'LIVerbs']\n",
    "cols = ([col for col in inserted_cols if col in dfTrump] \n",
    "        + [col for col in dfTrump if col not in inserted_cols])\n",
    "dfTrump = dfTrump[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA's with 0s as in this dataset, NAN represent the feature NOT occuring in a particular document.\n",
    "dfReagan = dfReagan.fillna(0)\n",
    "dfBush = dfBush.fillna(0)\n",
    "dfTrump = dfTrump.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output \n",
    "dfReagan.to_csv('testReagan.csv')\n",
    "dfBush.to_csv('testBush.csv')\n",
    "dfTrump.to_csv('testTrump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(testpath + \"dates.csv\")\n",
    "b = pd.read_csv(testpath + \"testReagan.csv\")\n",
    "\n",
    "c = pd.read_csv(testpath + \"dates2.csv\")\n",
    "d = pd.read_csv(testpath + \"testBush.csv\")\n",
    "\n",
    "e = pd.read_csv(testpath + \"dates3.csv\")\n",
    "f = pd.read_csv(testpath + \"testTrump.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['JDate'] = [datetime.datetime.strptime(x, '%d/%m/%Y') for x in a['Date']]\n",
    "c['JDate'] = [datetime.datetime.strptime(x, '%d/%m/%Y') for x in c['Date']]\n",
    "e['JDate'] = [datetime.datetime.strptime(x, '%d/%m/%Y') for x in e['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Julian'] = [get_julian_datetime(x) for x in a['JDate']]\n",
    "c['Julian'] = [get_julian_datetime(x) for x in c['JDate']]\n",
    "e['Julian'] = [get_julian_datetime(x) for x in e['JDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReagan = a.merge(b, on='Filename')\n",
    "dfBush = c.merge(d, on='Filename')\n",
    "dfTrump = e.merge(f, on='Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReagan = dfReagan.sort_values(by=['JDate'])\n",
    "dfBush = dfBush.sort_values(by=['JDate'])\n",
    "dfTrump = dfTrump.sort_values(by=['JDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new labels (Index is in order of article date)\n",
    "dfReagan = dfReagan.reset_index()\n",
    "dfReagan['index'] = dfReagan.index\n",
    "dfBush = dfBush.reset_index()\n",
    "dfBush['index'] = dfBush.index\n",
    "dfTrump = dfTrump.reset_index()\n",
    "dfTrump['index'] = dfTrump.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Redundant Columns\n",
    "dfReagan = dfReagan.drop(['Unnamed: 0'], axis=1)\n",
    "dfBush = dfBush.drop(['Unnamed: 0'], axis=1)\n",
    "dfTrump = dfTrump.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some new aggregate columns\n",
    "dfReagan['Nouns'] = dfReagan['NN'] + dfReagan['NNS']+ dfReagan['NNP'] + dfReagan['NNPS']\n",
    "dfReagan['Nouns/100'] = dfReagan['Nouns'] / 100\n",
    "dfReagan['NounsNormalised'] = dfReagan['Nouns'] / dfReagan['WordCount']\n",
    "dfReagan['Adjectives'] = dfReagan['JJ'] + dfReagan['JJR'] + dfReagan['JJS']\n",
    "dfReagan['Adjectives/100'] = dfReagan['Adjectives'] / 100\n",
    "dfReagan['AdjectivesNormalised'] = dfReagan['Adjectives'] / dfReagan['WordCount']\n",
    "dfReagan['Adverbs'] = dfReagan['RB'] + dfReagan['RBR'] + dfReagan['RBS']\n",
    "dfReagan['Adverbs/100'] = dfReagan['Adverbs'] / 100\n",
    "dfReagan['AdverbsNormalised'] = dfReagan['Adverbs'] / dfReagan['WordCount']\n",
    "dfReagan['Verbs'] = dfReagan['VB'] + dfReagan['VBD'] + dfReagan['VBG'] + dfReagan['VBN'] + dfReagan['VBP'] + dfReagan['VBZ']\n",
    "dfReagan['Verbs/100'] = dfReagan['Verbs'] / 100\n",
    "dfReagan['VerbsNormalised'] = dfReagan['Verbs'] / dfReagan['WordCount']\n",
    "dfReagan['Pronouns'] = dfReagan['PRP'] + dfReagan['PRP$']\n",
    "dfReagan['PronounsNormalised'] = dfReagan['Pronouns'] / dfReagan['WordCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some new aggregate columns\n",
    "dfBush['Nouns'] = dfBush['NN'] + dfBush['NNS']+ dfBush['NNP'] + dfBush['NNPS']\n",
    "dfBush['Nouns/100'] = dfBush['Nouns'] / 100\n",
    "dfBush['NounsNormalised'] = dfBush['Nouns'] / dfBush['WordCount']\n",
    "dfBush['Adjectives'] = dfBush['JJ'] + dfBush['JJR'] + dfBush['JJS']\n",
    "dfBush['Adjectives/100'] = dfBush['Adjectives'] / 100\n",
    "dfBush['AdjectivesNormalised'] = dfBush['Adjectives'] / dfBush['WordCount']\n",
    "dfBush['Adverbs'] = dfBush['RB'] + dfBush['RBR'] + dfBush['RBS']\n",
    "dfBush['Adverbs/100'] = dfBush['Adverbs'] / 100\n",
    "dfBush['AdverbsNormalised'] = dfBush['Adverbs'] / dfBush['WordCount']\n",
    "dfBush['Verbs'] = dfBush['VB'] + dfBush['VBD'] + dfBush['VBG'] + dfBush['VBN'] + dfBush['VBP'] + dfBush['VBZ']\n",
    "dfBush['Verbs/100'] = dfBush['Verbs'] / 100\n",
    "dfBush['VerbsNormalised'] = dfBush['Verbs'] / dfBush['WordCount']\n",
    "dfBush['Pronouns'] = dfBush['PRP'] + dfBush['PRP$']\n",
    "dfBush['PronounsNormalised'] = dfBush['Pronouns'] / dfBush['WordCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some new aggregate columns\n",
    "dfTrump['Nouns'] = dfTrump['NN'] + dfTrump['NNS']+ dfTrump['NNP'] + dfTrump['NNPS']\n",
    "dfTrump['Nouns/100'] = dfTrump['Nouns'] / 100\n",
    "dfTrump['NounsNormalised'] = dfTrump['Nouns'] / dfTrump['WordCount']\n",
    "dfTrump['Adjectives'] = dfTrump['JJ'] + dfTrump['JJR'] + dfTrump['JJS']\n",
    "dfTrump['Adjectives/100'] = dfTrump['Adjectives'] / 100\n",
    "dfTrump['AdjectivesNormalised'] = dfTrump['Adjectives'] / dfTrump['WordCount']\n",
    "dfTrump['Adverbs'] = dfTrump['RB'] + dfTrump['RBR'] + dfTrump['RBS']\n",
    "dfTrump['Adverbs/100'] = dfTrump['Adverbs'] / 100\n",
    "dfTrump['AdverbsNormalised'] = dfTrump['Adverbs'] / dfTrump['WordCount']\n",
    "dfTrump['Verbs'] = dfTrump['VB'] + dfTrump['VBD'] + dfTrump['VBG'] + dfTrump['VBN'] + dfTrump['VBP'] + dfTrump['VBZ']\n",
    "dfTrump['Verbs/100'] = dfTrump['Verbs'] / 100\n",
    "dfTrump['VerbsNormalised'] = dfTrump['Verbs'] / dfTrump['WordCount']\n",
    "dfTrump['Pronouns'] = dfTrump['PRP'] + dfTrump['PRP$']\n",
    "dfTrump['PronounsNormalised'] = dfTrump['Pronouns'] / dfTrump['WordCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to split data here\n",
    "Logic\n",
    "For dfRR where Date is between 01/01/1981 and 31/01/1985 copy data into dfRRTerm1\n",
    "For dfRR where Date is not between 01/01/1981 and 31/01/1985 copy data into dfRRTerm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReaganTerm1 = dfReagan[dfReagan.JDate < pd.Timestamp(1985, 1, 31)]\n",
    "dfReaganTerm2 = dfReagan[dfReagan.JDate > pd.Timestamp(1985, 1, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReaganTerm1 = dfReaganTerm1.reset_index()\n",
    "dfReaganTerm1['index'] = dfReaganTerm1.index\n",
    "dfReaganTerm2 = dfReaganTerm2.reset_index()\n",
    "dfReaganTerm2['index'] = dfReaganTerm2.index\n",
    "\n",
    "dfReaganTerm1 = dfReaganTerm1.drop(['level_0'], axis=1)\n",
    "dfReaganTerm2 = dfReaganTerm2.drop(['level_0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Target Variable\n",
    "yReagan = dfReagan['index']\n",
    "yReaganTerm1 = dfReaganTerm1['index']\n",
    "yReaganTerm2 = dfReaganTerm2['index']\n",
    "yBush = dfBush['index']\n",
    "yTrump = dfTrump['index']\n",
    "\n",
    "#yRR = dfRR['Julian']\n",
    "#yGWHB = dfGWHB['Julian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to csv files\n",
    "dfReagan.to_csv('Reagan.csv')\n",
    "dfBush.to_csv('Bush.csv')\n",
    "dfTrump.to_csv('Trump.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsReagan = pd.DataFrame()\n",
    "columnsReagan = list(dfReagan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsReagan.remove('index')\n",
    "columnsReagan.remove('Filename')\n",
    "columnsReagan.remove('Date')\n",
    "columnsReagan.remove('JDate')\n",
    "columnsReagan.remove('Julian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joe/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "for i in columnsReagan:\n",
    "    r, p = pearsonr(dfReagan[i], dfReagan['index'])\n",
    "    pearsonResults = {'Index': i, 'RSquared':r, 'P-Value': p}\n",
    "    resultsReagan = resultsReagan.append(pearsonResults, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsBush = pd.DataFrame()\n",
    "columnsBush = list(dfBush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsBush.remove('index')\n",
    "columnsBush.remove('Filename')\n",
    "columnsBush.remove('Date')\n",
    "columnsBush.remove('JDate')\n",
    "columnsBush.remove('Julian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joe/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "for i in columnsBush:\n",
    "    r, p = pearsonr(dfBush[i], dfBush['index'])\n",
    "    pearsonResults = {'Index': i, 'RSquared':r, 'P-Value': p}\n",
    "    resultsBush = resultsBush.append(pearsonResults, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsTrump = pd.DataFrame()\n",
    "columnsTrump = list(dfTrump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsTrump.remove('index')\n",
    "columnsTrump.remove('Filename')\n",
    "columnsTrump.remove('Date')\n",
    "columnsTrump.remove('JDate')\n",
    "columnsTrump.remove('Julian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joe/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "for i in columnsTrump:\n",
    "    r, p = pearsonr(dfTrump[i], dfTrump['index'])\n",
    "    pearsonResults = {'Index': i, 'RSquared':r, 'P-Value': p}\n",
    "    resultsTrump = resultsTrump.append(pearsonResults, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>RSquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NounsNormalised</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.708304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Analytic</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.658395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.586757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniqueWords</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.564363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Nouns/100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.561273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Nouns</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.561273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WDT</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-0.520333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.518294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>article</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.513836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-0.497892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Adjectives/100</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.495030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Adjectives</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.495030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Sixltr</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>-0.465428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>work</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>-0.454517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>AdjectivesNormalised</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>-0.406848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>-0.399314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IN</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>-0.389945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NNS</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>-0.381235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNP</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>-0.354851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>number</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>-0.354281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>focusfuture</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>-0.351894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VBN</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>-0.332324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WC</td>\n",
       "      <td>0.025867</td>\n",
       "      <td>-0.328397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>home</td>\n",
       "      <td>0.027763</td>\n",
       "      <td>-0.324557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CD</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>-0.320638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>prep</td>\n",
       "      <td>0.030070</td>\n",
       "      <td>-0.320166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>0.030356</td>\n",
       "      <td>-0.319641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>WP$</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>-0.319627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VBP</td>\n",
       "      <td>0.031336</td>\n",
       "      <td>-0.317875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>relativ</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>-0.315705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>0.033192</td>\n",
       "      <td>-0.314649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>-0.308392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WPS</td>\n",
       "      <td>0.046013</td>\n",
       "      <td>-0.295710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>anger</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>0.293173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VBD</td>\n",
       "      <td>0.045228</td>\n",
       "      <td>0.296736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>we</td>\n",
       "      <td>0.043901</td>\n",
       "      <td>0.298503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NSNouns</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>0.314511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>body</td>\n",
       "      <td>0.023568</td>\n",
       "      <td>0.333385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>negate</td>\n",
       "      <td>0.022443</td>\n",
       "      <td>0.335974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>nonflu</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>0.344140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.351955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>adverb</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.354884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>informal</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.357307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FW</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>0.359800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>VerbsNormalised</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.366555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>verb</td>\n",
       "      <td>0.012164</td>\n",
       "      <td>0.366797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hear</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.404747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Clout</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.411670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>they</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.412537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>AdverbsNormalised</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.415097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>differ</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.418351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>focuspast</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.422839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>certain</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.457776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Dic</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.494909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>shehe</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.505852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>male</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.554273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pronoun</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.641975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>PronounsNormalised</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.652309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>conj</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.658409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>function</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ppron</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>social</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Index  P-Value  RSquared\n",
       "143       NounsNormalised 0.000000 -0.708304\n",
       "49               Analytic 0.000001 -0.658395\n",
       "20                     NN 0.000018 -0.586757\n",
       "2             UniqueWords 0.000044 -0.564363\n",
       "142             Nouns/100 0.000050 -0.561273\n",
       "141                 Nouns 0.000050 -0.561273\n",
       "40                    WDT 0.000210 -0.520333\n",
       "16                     JJ 0.000225 -0.518294\n",
       "65                article 0.000260 -0.513836\n",
       "39                    VBZ 0.000430 -0.497892\n",
       "145        Adjectives/100 0.000470 -0.495030\n",
       "144            Adjectives 0.000470 -0.495030\n",
       "54                 Sixltr 0.001117 -0.465428\n",
       "117                  work 0.001508 -0.454517\n",
       "146  AdjectivesNormalised 0.005017 -0.406848\n",
       "13                     DT 0.005975 -0.399314\n",
       "15                     IN 0.007386 -0.389945\n",
       "23                    NNS 0.008948 -0.381235\n",
       "21                    NNP 0.015529 -0.354851\n",
       "75                 number 0.015707 -0.354281\n",
       "112           focusfuture 0.016474 -0.351894\n",
       "37                    VBN 0.024042 -0.332324\n",
       "48                     WC 0.025867 -0.328397\n",
       "119                  home 0.027763 -0.324557\n",
       "12                     CD 0.029814 -0.320638\n",
       "66                   prep 0.030070 -0.320166\n",
       "1               WordCount 0.030356 -0.319641\n",
       "46                    WP$ 0.030364 -0.319627\n",
       "38                    VBP 0.031336 -0.317875\n",
       "113               relativ 0.032575 -0.315705\n",
       "8                       , 0.033192 -0.314649\n",
       "109                  risk 0.037053 -0.308392\n",
       "53                    WPS 0.046013 -0.295710\n",
       "81                  anger 0.048001  0.293173\n",
       "35                    VBD 0.045228  0.296736\n",
       "60                     we 0.043901  0.298503\n",
       "5                 NSNouns 0.033274  0.314511\n",
       "100                  body 0.023568  0.333385\n",
       "70                 negate 0.022443  0.335974\n",
       "127                nonflu 0.019188  0.344140\n",
       "88                cogproc 0.016454  0.351955\n",
       "68                 adverb 0.015518  0.354884\n",
       "123              informal 0.014779  0.357307\n",
       "45                     FW 0.014049  0.359800\n",
       "152       VerbsNormalised 0.012226  0.366555\n",
       "71                   verb 0.012164  0.366797\n",
       "97                   hear 0.005270  0.404747\n",
       "50                  Clout 0.004477  0.411670\n",
       "63                   they 0.004385  0.412537\n",
       "149     AdverbsNormalised 0.004124  0.415097\n",
       "94                 differ 0.003812  0.418351\n",
       "110             focuspast 0.003416  0.422839\n",
       "93                certain 0.001380  0.457776\n",
       "55                    Dic 0.000471  0.494909\n",
       "62                  shehe 0.000335  0.505852\n",
       "87                   male 0.000064  0.554273\n",
       "57                pronoun 0.000002  0.641975\n",
       "154    PronounsNormalised 0.000001  0.652309\n",
       "69                   conj 0.000001  0.658409\n",
       "56               function 0.000000  0.694679\n",
       "58                  ppron 0.000000  0.716623\n",
       "83                 social 0.000000  0.737041"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsetReagan = pd.DataFrame()\n",
    "subsetReagan = resultsReagan.loc[resultsReagan['P-Value'] < 0.05]\n",
    "subsetReagan = subsetReagan.sort_values(by=['RSquared'])\n",
    "subsetReagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>RSquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Dash</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.606136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.582767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Colon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.459076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>conj</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.447959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fillers</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.357945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EX</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.338771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>-0.302863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLU</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>-0.280432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NNP</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.272823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RP</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>-0.262942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>WPS</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>-0.257825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniqueWords</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.253113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FW</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>-0.238857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PRP$</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>-0.237769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>discrep</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>-0.232020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IN</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>-0.226965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>SemiC</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>-0.222630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>VBD</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>-0.218828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Nouns</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>-0.214048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Nouns/100</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>-0.214048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>-0.212856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>differ</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>-0.212572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>0.015583</td>\n",
       "      <td>-0.210150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WC</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>-0.208487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>-0.208115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Exclam</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>-0.207415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LIVerbs</td>\n",
       "      <td>0.018469</td>\n",
       "      <td>-0.204838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>-0.201838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RB</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>-0.201548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Adverbs</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>-0.200957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Adverbs/100</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>-0.200957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MD</td>\n",
       "      <td>0.021612</td>\n",
       "      <td>-0.199818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>-0.197196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>-0.193002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Adjectives/100</td>\n",
       "      <td>0.026708</td>\n",
       "      <td>-0.192878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Adjectives</td>\n",
       "      <td>0.026708</td>\n",
       "      <td>-0.192878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>negate</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>-0.187362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Pronouns</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>-0.185570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VBN</td>\n",
       "      <td>0.037478</td>\n",
       "      <td>-0.181307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cause</td>\n",
       "      <td>0.037957</td>\n",
       "      <td>-0.180861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VB</td>\n",
       "      <td>0.038228</td>\n",
       "      <td>-0.180611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TO</td>\n",
       "      <td>0.040403</td>\n",
       "      <td>-0.178657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PRP</td>\n",
       "      <td>0.041892</td>\n",
       "      <td>-0.177368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Verbs</td>\n",
       "      <td>0.043043</td>\n",
       "      <td>-0.176399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Verbs/100</td>\n",
       "      <td>0.043043</td>\n",
       "      <td>-0.176399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>feel</td>\n",
       "      <td>0.043785</td>\n",
       "      <td>-0.175786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>i</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>-0.175210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NNS</td>\n",
       "      <td>0.047241</td>\n",
       "      <td>-0.173037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>number</td>\n",
       "      <td>0.047306</td>\n",
       "      <td>0.172987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Apostro</td>\n",
       "      <td>0.044091</td>\n",
       "      <td>0.175535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>time</td>\n",
       "      <td>0.035619</td>\n",
       "      <td>0.183083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>posemo</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>0.183499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ipron</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.190978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>``</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.198106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTR</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.199254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>''</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>0.200070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>social</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.200876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>affiliation</td>\n",
       "      <td>0.018641</td>\n",
       "      <td>0.204546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>verb</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>0.204996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Dic</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>0.215308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>focusfuture</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.220430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>adj</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.223920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>VerbsNormalised</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.242506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sad</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.249213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>money</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.251188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>reward</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.288671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>we</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.289680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>work</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.290711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Clout</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.294202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>home</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.295501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>drives</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.305307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Quote</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.329435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Period</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.330214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>achieve</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.356666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Index  P-Value  RSquared\n",
       "137             Dash 0.000000 -0.606136\n",
       "9                  : 0.000000 -0.582767\n",
       "133            Colon 0.000000 -0.459076\n",
       "70              conj 0.000000 -0.447959\n",
       "4            Fillers 0.000025 -0.357945\n",
       "13                EX 0.000071 -0.338771\n",
       "10                CC 0.000416 -0.302863\n",
       "3                MLU 0.001126 -0.280432\n",
       "20               NNP 0.001551 -0.272823\n",
       "28                RP 0.002319 -0.262942\n",
       "54               WPS 0.002839 -0.257825\n",
       "2        UniqueWords 0.003409 -0.253113\n",
       "46                FW 0.005812 -0.238857\n",
       "24              PRP$ 0.006046 -0.237769\n",
       "92           discrep 0.007429 -0.232020\n",
       "14                IN 0.008869 -0.226965\n",
       "134            SemiC 0.010294 -0.222630\n",
       "32               VBD 0.011707 -0.218828\n",
       "142            Nouns 0.013722 -0.214048\n",
       "143        Nouns/100 0.013722 -0.214048\n",
       "89           cogproc 0.014269 -0.212856\n",
       "95            differ 0.014402 -0.212572\n",
       "1          WordCount 0.015583 -0.210150\n",
       "49                WC 0.016441 -0.208487\n",
       "7                  , 0.016638 -0.208115\n",
       "136           Exclam 0.017016 -0.207415\n",
       "6            LIVerbs 0.018469 -0.204838\n",
       "15                JJ 0.020296 -0.201838\n",
       "25                RB 0.020481 -0.201548\n",
       "148          Adverbs 0.020862 -0.200957\n",
       "149      Adverbs/100 0.020862 -0.200957\n",
       "18                MD 0.021612 -0.199818\n",
       "12                DT 0.023429 -0.197196\n",
       "19                NN 0.026607 -0.193002\n",
       "146   Adjectives/100 0.026708 -0.192878\n",
       "145       Adjectives 0.026708 -0.192878\n",
       "71            negate 0.031457 -0.187362\n",
       "154         Pronouns 0.033147 -0.185570\n",
       "34               VBN 0.037478 -0.181307\n",
       "91             cause 0.037957 -0.180861\n",
       "31                VB 0.038228 -0.180611\n",
       "29                TO 0.040403 -0.178657\n",
       "23               PRP 0.041892 -0.177368\n",
       "151            Verbs 0.043043 -0.176399\n",
       "152        Verbs/100 0.043043 -0.176399\n",
       "99              feel 0.043785 -0.175786\n",
       "60                 i 0.044491 -0.175210\n",
       "22               NNS 0.047241 -0.173037\n",
       "76            number 0.047306  0.172987\n",
       "139          Apostro 0.044091  0.175535\n",
       "117             time 0.035619  0.183083\n",
       "79            posemo 0.035194  0.183499\n",
       "65             ipron 0.028269  0.190978\n",
       "42                `` 0.022785  0.198106\n",
       "0                TTR 0.021992  0.199254\n",
       "40                '' 0.021444  0.200070\n",
       "84            social 0.020914  0.200876\n",
       "106      affiliation 0.018641  0.204546\n",
       "72              verb 0.018378  0.204996\n",
       "56               Dic 0.013163  0.215308\n",
       "113      focusfuture 0.011092  0.220430\n",
       "73               adj 0.009850  0.223920\n",
       "153  VerbsNormalised 0.005085  0.242506\n",
       "83               sad 0.003956  0.249213\n",
       "121            money 0.003670  0.251188\n",
       "109           reward 0.000789  0.288671\n",
       "61                we 0.000754  0.289680\n",
       "118             work 0.000721  0.290711\n",
       "51             Clout 0.000617  0.294202\n",
       "120             home 0.000582  0.295501\n",
       "105           drives 0.000371  0.305307\n",
       "138            Quote 0.000115  0.329435\n",
       "131           Period 0.000110  0.330214\n",
       "107          achieve 0.000027  0.356666"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsetBush = pd.DataFrame()\n",
    "subsetBush = resultsBush.loc[resultsBush['P-Value'] < 0.05]\n",
    "subsetBush = subsetBush.sort_values(by=['RSquared'])\n",
    "subsetBush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>RSquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>focusfuture</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>-0.480664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>adj</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>-0.463114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>adverb</td>\n",
       "      <td>0.019732</td>\n",
       "      <td>-0.430535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>AdverbsNormalised</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>-0.368497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>motion</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>-0.368377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNPS</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>0.393352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>power</td>\n",
       "      <td>0.034658</td>\n",
       "      <td>0.393574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>OtherP</td>\n",
       "      <td>0.033605</td>\n",
       "      <td>0.395701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CD</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>0.421288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>number</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>0.435983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:</td>\n",
       "      <td>0.015073</td>\n",
       "      <td>0.446927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>$</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.496601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Dash</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.496990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>they</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.500095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Index  P-Value  RSquared\n",
       "112        focusfuture 0.008307 -0.480664\n",
       "72                 adj 0.011407 -0.463114\n",
       "68              adverb 0.019732 -0.430535\n",
       "149  AdverbsNormalised 0.049187 -0.368497\n",
       "114             motion 0.049267 -0.368377\n",
       "21                NNPS 0.034769  0.393352\n",
       "107              power 0.034658  0.393574\n",
       "140             OtherP 0.033605  0.395701\n",
       "11                  CD 0.022845  0.421288\n",
       "75              number 0.018067  0.435983\n",
       "9                    : 0.015073  0.446927\n",
       "43                   $ 0.006140  0.496601\n",
       "136               Dash 0.006094  0.496990\n",
       "63                they 0.005735  0.500095"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsetTrump = pd.DataFrame()\n",
    "subsetTrump = resultsTrump.loc[resultsTrump['P-Value'] < 0.05]\n",
    "subsetTrump = subsetTrump.sort_values(by=['RSquared'])\n",
    "subsetTrump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated number of days from first speech to last speech. Better indicator of progress over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 60.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Mean Length of Utterance over time for RR\n",
    "xs = dfReagan['index']\n",
    "ys = dfReagan['Analytic']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)\n",
    "plt.ylim((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Mean Length of Utterance over time for RR\n",
    "xs = dfReagan['index']\n",
    "ys = dfReagan['NounsNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)\n",
    "plt.ylim((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Length of Utterance over time for GWHB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['MLU']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)\n",
    "plt.ylim((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Length of Utterance over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['MLU']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)\n",
    "plt.ylim((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Unique Words over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['UniqueWords']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)\n",
    "plt.ylim((0, 1200))\n",
    "plt.suptitle('Ronald Reagan - Unique Words')\n",
    "plt.savefig('RRUniqueWords.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Unique Words over time for GWHB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['UniqueWords']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)\n",
    "plt.suptitle('George Bush Snr - Unique Words')\n",
    "plt.savefig('GWHBUniqueWords.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Unique Words over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['UniqueWords']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Token Type Ratio over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['TTR']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Token Type Ratio over time for GWHB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['TTR']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Token Type Ratio over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['TTR']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Word Count over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['WordCount']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Word Count over time for GHWB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['WordCount']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Word Count over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['WordCount']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1)\n",
    "plt.plot(xs, ys, 'o')\n",
    "plt.plot(xs, trend[1] + trend[0] * xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Nouns per 100 over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['Nouns/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Nouns per 100 over time for GHWB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['Nouns/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Nouns per 100 over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['Nouns/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Verbs per 100 over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['Verbs/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Verbs per 100 over time for GHWB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['Verbs/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Verbs per 100 over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['Verbs/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Adjectives per 100 over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['Adjectives/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Adjectives per 100 over time for GHWB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['Adjectives/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Adjectives per 100 over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['Adjectives/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Adverbs per 100 over time for RR\n",
    "xs = dfRR['index']\n",
    "ys = dfRR['Adverbs/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Adverbs per 100 over time for GHWB\n",
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['Adverbs/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Adverbs per 100 over time for DJT\n",
    "xs = dfDJT['index']\n",
    "ys = dfDJT['Adverbs/100']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfRR['index']\n",
    "ys = dfRR['NounsNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)\n",
    "plt.suptitle('RR - Nouns Normalised')\n",
    "plt.savefig('RRNounsNorm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['NounsNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)\n",
    "plt.suptitle('GWHB - Nouns Normalised')\n",
    "plt.savefig('GWHBNounsNorm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfDJT['index']\n",
    "ys = dfDJT['NounsNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)\n",
    "plt.suptitle('DJT - Nouns Normalised')\n",
    "plt.savefig('DJTNounsNorm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfRR['index']\n",
    "ys = dfRR['AdjectivesNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['AdjectivesNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfDJT['index']\n",
    "ys = dfDJT['AdjectivesNormalised']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfRR['index']\n",
    "ys = dfRR['Fillers']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['Fillers']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfDJT['index']\n",
    "ys = dfDJT['Fillers']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfRR['index']\n",
    "ys = dfRR['NSNouns']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)\n",
    "plt.suptitle('Ronald Reagan - Non Specific Nouns')\n",
    "plt.savefig('RRNSNouns.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['NSNouns']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfDJT['index']\n",
    "ys = dfDJT['NSNouns']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)\n",
    "plt.suptitle('Donald Trump - Non Specific Nouns')\n",
    "plt.savefig('DJTNSNouns.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfRR['index']\n",
    "ys = dfRR['LIVerbs']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfGWHB['index']\n",
    "ys = dfGWHB['LIVerbs']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = dfDJT['index']\n",
    "ys = dfDJT['LIVerbs']\n",
    "xs = np.asarray(xs)\n",
    "trend = np.polyfit(xs, ys, 1) # fit a straight line\n",
    "plt.plot(xs, ys,'o')\n",
    "plt.plot(xs,trend[1]+trend[0]*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsRR = dfRR['Filename']\n",
    "dfRR = dfRR.drop(['Filename', 'JDate', 'Julian', 'Date', 'index'], axis=1)\n",
    "labelsGHWB = dfGWHB['Filename']\n",
    "dfGWHB = dfGWHB.drop(['Filename', 'JDate', 'Julian', 'Date', 'index'], axis=1)\n",
    "labelsDJT = dfDJT['Filename']\n",
    "dfDJT = dfDJT.drop(['Filename', 'JDate', 'Julian', 'Date', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "yRRscaled = preprocessing.scale(yRR)\n",
    "dfRRscaled = preprocessing.scale(dfRR)\n",
    "\n",
    "yGWHBscaled = preprocessing.scale(yGWHB)\n",
    "dfGWHBscaled = preprocessing.scale(dfGWHB)\n",
    "\n",
    "yDJTscaled = preprocessing.scale(yDJT)\n",
    "dfDJTscaled = preprocessing.scale(dfDJT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- LINEAR REGRESSION --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGridRR = pd.DataFrame()\n",
    "for i in range (1,1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dfRRscaled, yRR, test_size=0.20)\n",
    "    # fit a model\n",
    "    lm = linear_model.LinearRegression()\n",
    "    model = lm.fit(X_train, y_train)\n",
    "    predictions = lm.predict(X_test)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(predictions, y_test)\n",
    "    resultsTuple = {'Slope': slope, 'intercept': intercept, 'r_value': r_value,\n",
    "                    'p_value':p_value, \n",
    "                    'std_err':std_err}\n",
    "    resultsGridRR = resultsGridRR.append(resultsTuple, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGridGWHB = pd.DataFrame()\n",
    "for i in range (1,1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dfGWHBscaled, yGWHB, test_size=0.20)\n",
    "    # fit a model\n",
    "    lm = linear_model.LinearRegression()\n",
    "    model = lm.fit(X_train, y_train)\n",
    "    predictions = lm.predict(X_test)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(predictions, y_test)\n",
    "    resultsTuple = {'Slope': slope, 'intercept': intercept, 'r_value': r_value,\n",
    "                    'p_value':p_value, \n",
    "                    'std_err':std_err}\n",
    "    resultsGridGWHB = resultsGridGWHB.append(resultsTuple, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGridDJT = pd.DataFrame()\n",
    "for i in range (1,1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dfDJTscaled, yDJT, test_size=0.20)\n",
    "    # fit a model\n",
    "    lm = linear_model.LinearRegression()\n",
    "    model = lm.fit(X_train, y_train)\n",
    "    predictions = lm.predict(X_test)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(predictions, y_test)\n",
    "    resultsTuple = {'Slope': slope, 'intercept': intercept, 'r_value': r_value,\n",
    "                    'p_value':p_value, \n",
    "                    'std_err':std_err}\n",
    "    resultsGridDJT = resultsGridDJT.append(resultsTuple, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGridRR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGridGWHB.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGridDJT.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- GAUSSIAN PROCESSES --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/CAMPUS/alcantaj/Dropbox/'\n",
    "path = '/Users/Joe/Documents/Coding/'\n",
    "bush_df = pd.read_csv(path + 'Bush.csv')\n",
    "reagan_df = pd.read_csv(path + 'Reagan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = reagan_df['Julian'].min() # Smallest Julian Date\n",
    "maximum = reagan_df['Julian'].max() # Maximum Julian Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan_df['NormalisedDate'] = (reagan_df['Julian'] - minimum) / (maximum - minimum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan_df['CountDays'] = reagan_df['Julian'] - minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan_df['CountDaysN'] = reagan_df['CountDays'] / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO DROP DATA COLUMNS HERE BEFORE RUN MODEL\n",
    "reagan_df = reagan_df.drop(['Unnamed: 0', 'Filename', 'index','Date', 'JDate', 'Julian',\n",
    "                           'NormalisedDate', 'CountDays'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = reagan_df['CountDaysN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_target = target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(185, (1e-2, 1e4))\n",
    "# kernel = RBF(10, (1e-2, 1e2))\n",
    "gp = GaussianProcessRegressor(kernel = kernel, n_restarts_optimizer=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(reagan_df, target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.asarray(y_train)\n",
    "variables = np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "model = gp.fit(variables, target) # This looks fine according to documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, sigma = gp.predict(np.asarray(X_test), return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot\n",
    "plt.figure()\n",
    "xs = [x for x in range(0, 9)]\n",
    "ys = [x for x in range(0, 9)]\n",
    "plt.plot(xs, ys)\n",
    "plt.plot(y_test, y_pred, 'o', linestyle='None')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis(xscale = 0, yscale = 0)\n",
    "plt.errorbar(y_test, y_pred, yerr=1.9600 * sigma, elinewidth=1, fillstyle='full', linestyle ='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqErr = (y_test - y_pred)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_test':y_test, 'y_pred':y_pred, 'sigma': sigma, 'Squared Error': sqErr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = sum(sqErr) / len(sqErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bush_df = pd.read_csv(path + 'Bush.csv')\n",
    "reagan_df = pd.read_csv(path + 'Reagan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = reagan_df['Julian'].min() # Smallest Julian Date\n",
    "maximum = reagan_df['Julian'].max() # Maximum Julian Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan_df['NormalisedDate'] = (reagan_df['Julian'] - minimum) / (maximum - minimum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan_df['CountDays'] = reagan_df['Julian'] - minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan_df['CountDaysN'] = reagan_df['CountDays'] / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO DROP DATA COLUMNS HERE BEFORE RUN MODEL\n",
    "reagan_df = reagan_df.drop(['Unnamed: 0', 'Filename', 'index','Date', 'JDate', 'Julian',\n",
    "                           'NormalisedDate', 'CountDays'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = reagan_df['CountDaysN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_target = target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(191, (1e-2, 1e4))\n",
    "# kernel = RBF(10, (1e-2, 1e2))\n",
    "gp = GaussianProcessRegressor(kernel = kernel, n_restarts_optimizer=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reagan_df, target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.DataFrame()\n",
    "for i in range(0, 999):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reagan_df, target, test_size=0.20)\n",
    "    targetVar = np.asarray(y_train)\n",
    "    variables = np.asarray(X_train)\n",
    "    model = gp.fit(variables, targetVar)\n",
    "    y_pred, sigma = gp.predict(np.asarray(X_test), return_std=True)\n",
    "    sqErr = (y_test - y_pred)**2\n",
    "    MSE = sum(sqErr)/len(sqErr)\n",
    "    tuple = {'MSE': MSE, 'gp.kernel':gp.kernel, 'gp.kernel_':gp.kernel_}\n",
    "    Results = Results.append(tuple, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean = Results['MSE'].mean()\n",
    "SD = Results['MSE'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Mean is', Mean)\n",
    "print('The SD is', SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
